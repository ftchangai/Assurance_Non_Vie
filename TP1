# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
# ENSAE - 3A - Actuariat de l'assurance non vie                   #
# Décembre 2016                                                   #
# Etudiants : François TOULE, Ulrich Mpeli                        #
# Enseignant : Arthur CHARPENTIER                                 #
# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

# == Préambule ====================================================
rm(list=ls())
cat("\014")

library(splines)
library(lsr)
library(MASS)
library(ROCR)
library(pROC)
library(tm)
library(utils)
library(SnowballC)
library(ggplot2)
library(rpart)
library(rpart.plot)
library(rattle)
library(tree)
library(hmeasure)
library(wordcloud)
library(texreg)
library(stargazer)
library(ade4)
library(doBy)
library(xlsx)
library(party)
library(ipred)
library(randomForest)
library(parallel)
library(ParallelPC)
library(ParallelForest)
library(doParallel)
library(dplyr)
library(class)
library(mgcv)

# == Get Data ===========================================

download.file(url="http://freakonometrics.free.fr/base_ensae_1.RData",destfile="base.RData")
load("base.RData")
pricing = read.csv2("http://freakonometrics.free.fr/pricing.csv")

# == Recherche et suppression des doublons ===========================================
data1 = base_ensae_1
descr = summary(data1)
table(duplicated(data1))
x = duplicated(data1)
data2 = data1[data1$PolNum==200114978,] # la ligne 129 est une duplication de la ligne 1
data2 = cbind(data1,x)
data2 = data2[data2$x=="FALSE",]
table(duplicated(data2))
summary(data2)

# == Brêve description des données ===========================================


table(data2$CalYear)/nrow(data2)
table(data2$Gender)/nrow(data2)
table(data2$Type)/nrow(data2)
table(data2$Category)/nrow(data2)
table(data2$Occupation)/nrow(data2)
table(data2$Adind)/nrow(data2)
table(data2$SubGroup2)/nrow(data2)
table(data2$Group2)/nrow(data2)
table(data2$Surv1)/nrow(data2)
table(data2$Surv2)/nrow(data2)
descr
## Proportion homme/femme

nb.Men = sum(data2$Gender == "Male")
nb.Women = sum(data2$Gender == "Female")
cat("La base de donnees est composee de", nb.Men, "hommes, soit", round(100*nb.Men/100000), 
    "% et", nb.Women, "femmes, soit" ,round(100*nb.Women/100000),"% .")


# Histogramme des âges
par(lend="butt")
dst = density(data2$Age, na.rm = TRUE)
dstM = density(data2$Age[data2$Gender == "Male"], na.rm = TRUE)
dstF = density(data2$Age[data2$Gender == "Female"], na.rm = TRUE)
hist(data2$Age, col = grey(0.9), border = grey(0.8),main = paste("Age des assurés"),
     xlab = "Age [ans]",proba = TRUE, xlim = c(15 , 75), ylim = c(0, max(dst$y)))
lines(dstM$x, nb.Men/100000*dstM$y, lwd = 3, col = "darkblue")
lines(dstF$x, nb.Women/100000*dstF$y, lwd = 3, lty = 2, col = "darkred")
lines(dst$x, dst$y)
legend("topright", inset = 0.008, legend = c("Female", "Male","All"), col = c("darkred","darkblue","black"),
       lty = c(2, 1,1), lwd = 2, pt.cex = 2)
rm(dst,dstM,dstF)


# == Traitement préliminaire des variables ===========================================

### Détection des effets non linéaires

## Age

reg1 = glm (Surv1 ~offset(log(Exppdays))+bs(Age,df=5) , data =data2 , family = binomial (link ="cloglog"))
summary(reg1)

reg2 = glm (Surv1 ~offset(log(Exppdays))+Age , data =data2 , family = binomial (link ="cloglog"))
summary(reg2)

reg3 = glm (Surv1 ~offset(log(Exppdays))+as.factor(Age) , data =data2 , family = binomial (link ="cloglog"))
summary(reg3)

u= seq (18 ,75 , by =1)
v=rep(365,length(u))
newd = data.frame(Age =u,Exppdays=v)

#en linéaire
y= predict(reg2 , newdata =newd , type ="response",se.fit = TRUE )

#discret
z= predict(reg3 , newdata =newd , type ="response",se.fit = TRUE )

#en spline
w=predict(reg1 , newdata =newd , type ="response",se.fit = TRUE )

#on trace pour montrer la non linéarité
plot (u,z$fit , col ="red",ylab = "Sinistralité", xlab = "Age", main="Non linéarité de l'âge")
lines(u,y$fit, col="blue")
lines(u,w$fit, col="green")
legend( 30,0.30,legend=c("Catégorielle","Linéaire","Splines linéaires M=6" ),col=c("red", "blue","green"),lty=1:1, cex=0.8)


#un échantillon aléatoire
base1=data2[sample(nrow(data2),80000),]


#les 20 000 restant
base2<-data2[!( data2$PolNum %in%  base1$PolNum),]

deg=seq(1,10,by=1)
vec_var_app=rep(0,10)
vec_var_test=rep(0,10)

#nombre de degré de liberté

for(i in 1:10){
  reg_app<- glm (Surv1 ~offset(log(Exppdays))+bs(Age,df=deg[i]) , data =base1 , family = binomial (link ="logit"))
  vec_var_app [i]=var(residuals(reg_app,type = "response"))
  reg_test<-glm (Surv1 ~offset(log(Exppdays))+bs(Age,df=deg[i]) , data =base2, family = binomial (link ="logit"))
  vec_var_test[i]=var(residuals(reg_test,type="response"))
}


plot(vec_var_app,ylab="Variance des résidus", xlab = "Degré du polynôme", col="blue",main="Variance des résidus en utilisant l'échantillon d'apprentissage")

lines(vec_var_app,ylab="Variance des résidus", xlab = "Degré du polynôme", col="blue",main="Variance des résidus en utilisant l'échantillon d'apprentissage")


plot(vec_var_test,ylab="Variance des résidus", xlab = "Degré du polynôme", col="blue",main="Variance des résidus en utilisant l'échantillon test")

lines(vec_var_test,ylab="Variance des résidus", xlab = "Degré du polynôme", col="blue",main="Variance des résidus en utilisant l'échantillon test")

#========================== Value ======================#


reg5 <- glm (Surv1 ~Value+offset(log(Exppdays)) , data =data2 , family = binomial (link ="logit"))
summary(reg5)


####???n découpe la valeur tous les 1000
max(data2$Value)
min(data2$Value)
point=seq(1000,50000,by=1000)
X=cut(data2$Value,breaks = point )

reg3 <- glm (Surv1 ~offset(log(Exppdays))+ cut(Value,breaks = point ) , data =data2 , family = binomial (link ="logit"))
summary(reg3)

u= seq (1000 ,50000 , by =1000)
v=rep(365,length(u))
newd = data.frame(Value =u, Exppdays=v)
y= predict(reg3 , newdata =newd , type ="response",se.fit = TRUE )

z= predict(reg5 , newdata =newd , type ="response",se.fit = TRUE )

plot (u,y$fit , col =" red ", xlab = "Valeur du véhcilue", ylab = "Sinistralité", main="Linéarité de Value")
lines(u,z$fit,col="blue")
legend( 10,0.175,legend=c("Catégorielle","continue, linéaire"),col=c("red", "blue"),lty=1:2, cex=0.8)



#============== Bonus =======================# 

##### pour le bonus
for(i in 1:10){
  reg_app<- glm (Surv1 ~offset(log(Exppdays))+bs(Bonus,df=deg[i]) , data =base1 , family = binomial (link ="cloglog"))
  vec_var_app [i]=var(residuals(reg_app,type = "response"))
  reg_test<-glm (Surv1 ~offset(log(Exppdays))+bs(Bonus,df=deg[i]) , data =base2, family = binomial (link ="cloglog"))
  vec_var_test[i]=var(residuals(reg_test,type="response"))
}
plot(vec_var_app,ylab="Variance des résidus", xlab = "Degré du polynôme", col="blue",main="Variance des résidus en utilisant l'échantillon d'apprentissage")
lines(vec_var_app,ylab="Variance des résidus", xlab = "Degré du polynôme", col="blue",main="Variance des résidus en utilisant l'échantillon d'apprentissage")


plot(vec_var_test,ylab="Variance des résidus", xlab = "Degré du polynôme", col="blue",main="Variance des résidus en utilisant l'échantillon test")
lines(vec_var_test,ylab="Variance des résidus", xlab = "Degré du polynôme", col="blue",main="Variance des résidus en utilisant l'échantillon test")



## Transformation des variables continues

par(mfrow=c(1,2))

arbre=rpart(Surv1~Age, data=data2,method="poisson",cp=4e-4, minsplit=50000) 
prp(arbre,type=2,extra=1 , box.col=5, main="Age")

arbre=rpart(Surv1~Group1, data=data2,method="poisson",cp=4e-4, minsplit=50000) 
prp(arbre,type=2,extra=1 , box.col=5, main="Group1")

arbre=rpart(Surv1~Bonus, data=data2,method="poisson",cp=4e-4, minsplit=30000) 
prp(arbre,type=2,extra=1, box.col=5, main="Bonus" )

arbre=rpart(Surv1~Poldur, data=data2,method="poisson",cp=4e-4, minsplit=15000) 
prp(arbre,type=2,extra=1, box.col=5, main="Poldur" )

arbre=rpart(Surv1~Value, data=data2,method="poisson",cp=4e-4, minsplit=15000) 
prp(arbre,type=2,extra=1, box.col=5, main="Value" )

arbre=rpart(Surv1~Density, data=data2,method="poisson",cp=4e-4, minsplit=15000) 
prp(arbre,type=2,extra=1, box.col=5, main="Density" )


data3=data2[,c(-2,-3,-17,-18,-20,-21)]

#data3$CAge = cut(data3$Age, breaks = c(18, 23, 29, 33, 47,59,75), include.lowest = TRUE)
data3$CAge = cut(data3$Age, breaks = c(18, 29, 47,75), include.lowest = TRUE)
table(data3$CAge)/nrow(data3)
data3$CBonus = cut(data3$Bonus, breaks = c(-50, -36, -16, 14, 64,150), include.lowest = TRUE)
table(data3$CBonus)/nrow(data3)
data3$CGroup1 = cut(data3$Group1, breaks = c(1, 9, 15, 20), include.lowest = TRUE)
table(data3$CGroup1)/nrow(data3)
data3$CPoldur = cut(data3$Poldur, breaks = c(0, 0.5, 4,15) , include.lowest = TRUE)
table(data3$CPoldur)/nrow(data3)
data3$CValue = cut(data3$Value, breaks = c(1000, 12999,49996) , include.lowest = TRUE)
table(data3$CValue)/nrow(data3)
data3$CDensity = cut(data3$Density, breaks = c(0,77.99,162.99,237.99,297.40) , include.lowest = TRUE)
table(data3$CDensity)/nrow(data3)

data4 = data3[,c(-5,-6,-7,-8,-9,-13)]
data5 = data4[,c(-1)]


## Regroupement des modalités des variables

#Type
reg =  glm (Surv1 ~offset(Exppdays)+Type, data = data5 , family = binomial (link ="logit"))
summary(reg)
data5$Type=relevel(data5$Type,"B")
reg = glm (Surv1 ~offset(Exppdays)+Type, data = data5 , family = binomial (link ="logit"))
summary(reg)
data5$Type=relevel(data5$Type,"C")
reg = glm (Surv1 ~offset(Exppdays)+Type, data = data5 , family = binomial (link ="logit"))
summary(reg)
data5$Type=relevel(data5$Type,"D")
reg = glm (Surv1 ~offset(Exppdays)+Type, data = data5 , family = binomial (link ="logit"))
summary(reg)
data5$Type=relevel(data5$Type,"E")
reg = glm (Surv1 ~offset(Exppdays)+Type, data = data5 , family = binomial (link ="logit"))
summary(reg)
data5$Type=relevel(data5$Type,"F")
reg = glm (Surv1 ~offset(Exppdays)+Type, data = data5 , family = binomial (link ="logit"))
summary(reg) # On ne peut regrouper les modalités de la variable Type


# Occupation

reg = glm (Surv1 ~offset(Exppdays)+Occupation, data = data5 , family = binomial (link ="logit"))
summary(reg)
data5$Occupation=relevel(data5$Occupation,"Housewife")
reg = glm (Surv1 ~offset(Exppdays)+Occupation, data = data5 , family = binomial (link ="logit"))
summary(reg)
data5$Occupation=relevel(data5$Occupation,"Retired")
reg = glm (Surv1 ~offset(Exppdays)+Occupation, data = data5 , family = binomial (link ="logit"))
summary(reg)
data5$Occupation=relevel(data5$Occupation,"Self-employed")
reg = glm (Surv1 ~offset(Exppdays)+Occupation, data = data5 , family = binomial (link ="logit"))
summary(reg)
data5$Occupation=relevel(data5$Occupation,"Unemployed")
reg = glm (Surv1 ~offset(Exppdays)+Occupation, data = data5 , family = binomial (link ="logit"))
summary(reg)

# Group2

reg = glm (Surv1 ~offset(Exppdays)+Group2, data = data5 , family = binomial (link ="logit"))
summary(reg)
data5$Group2=relevel(data5$Group2,"M")
reg = glm (Surv1 ~offset(Exppdays)+Group2, data = data5 , family = binomial (link ="logit"))
summary(reg)
data5$Group2=relevel(data5$Group2,"N")
reg = glm (Surv1 ~offset(Exppdays)+Group2, data = data5 , family = binomial (link ="logit"))
summary(reg)
data5$Group2=relevel(data5$Group2,"O")
reg = glm (Surv1 ~offset(Exppdays)+Group2, data = data5 , family = binomial (link ="logit"))
summary(reg)
data5$Group2=relevel(data5$Group2,"P")
reg = glm (Surv1 ~offset(Exppdays)+Group2, data = data5 , family = binomial (link ="logit"))
summary(reg)
data5$Group2=relevel(data5$Group2,"Q")
reg = glm (Surv1 ~offset(Exppdays)+Group2, data = data5 , family = binomial (link ="logit"))
summary(reg)
data5$Group2=relevel(data5$Group2,"R")
reg = glm (Surv1 ~offset(Exppdays)+Group2, data = data5 , family = binomial (link ="logit"))
summary(reg)
data5$Group2=relevel(data5$Group2,"S")
reg = glm (Surv1 ~offset(Exppdays)+Group2, data = data5 , family = binomial (link ="logit"))
summary(reg)
data5$Group2=relevel(data5$Group2,"T")
reg = glm (Surv1 ~offset(Exppdays)+Group2, data = data5 , family = binomial (link ="logit"))
summary(reg)
data5$Group2=relevel(data5$Group2,"U")
reg = glm (Surv1 ~offset(Exppdays)+Group2, data = data5 , family = binomial (link ="logit"))
summary(reg)

# SubGroup2

reg = glm (Surv1 ~offset(Exppdays)+SubGroup2, data = data5 , family = binomial (link ="logit"))
summary(reg)
data5$Group2=relevel(data5$Group2,"M")
reg = glm (Surv1 ~offset(Exppdays)+SubGroup2, data = data5 , family = binomial (link ="logit"))
summary(reg)



# == Sélection des variables ===========================================

## Test du Khi-deux

data6 = matrix(NA,ncol(data5),ncol(data5))
colnames(data6)= colnames(data5)
rownames(data6)= colnames(data5)

for (i in 1:ncol(data5)){
  for (j in 1:ncol(data5)){
    u = chisq.test(data5[,i],data5[,j])
    data6[i,j] = u$p.value
  }
}

## V de cramer

data7 = matrix(NA,ncol(data5),ncol(data5))
colnames(data7)= colnames(data5)
rownames(data7)= colnames(data5)

for (i in 1:ncol(data5)){
  for (j in 1:ncol(data5)){
    data7[i,j] = cramersV(table(data5[,i],data5[,j]))
     
  }
}


## Importance variable

data8 = data5[,c(-5,-6,-7)]
RF=randomForest((Surv1==1)~Type+Category+Occupation ,data = data5) 
²varImpPlot(RF,main="") 
importance (RF) 

data9 = data5[,c(-5,-7)]

#data9$Group21[data9$Group2 == "L"] = "LOPT"
#data9$Group21[data9$Group2 == "M"] = "MR"
#data9$Group21[data9$Group2 == "N"] = "NQ"
#data9$Group21[data9$Group2 == "O"] = "LOPT"
#data9$Group21[data9$Group2 == "P"] = "LOPT"
#data9$Group21[data9$Group2 == "Q"] = "NQ"
#data9$Group21[data9$Group2 == "R"] = "MR"
#data9$Group21[data9$Group2 == "S"] = "US"
#data9$Group21[data9$Group2 == "T"] = "LOPT"
#data9$Group21[data9$Group2 == "U"] = "US"

#data9 = data9[,c(-5)]
#table(data9$Group21)

cl = makeCluster(4)
registerDoParallel(cl)
rf = foreach(ntree=rep(1, 1), .combine= combine, .packages='randomForest') %dopar% {
  randomForest((Surv1==1)~.,
               data = data9, nodesize=20,
               ntree=ntree, importance=TRUE, keep.forest=TRUE)
}
stopCluster(cl)

varImpPlot(rf,main="") 
importance (rf) 

# Nuage des variables
par(mfrow=c(1,1))
var = c("Type","Category","Occupation","Adind","Group2","CAge","CGroup1","CBonus","CPoldur",
        "CValue","CDensity")
z = importance (rf)
freq = as.numeric(z[,2])
nvar = cbind(var,freq)
nvar = as.data.frame(nvar)

nvar$freq = rep(0,11)
nvar$freq[1] = 453.2760
nvar$freq[2] = 227.1715 
nvar$freq[3] = 367.3523
nvar$freq[4] = 119.8644
nvar$freq[5] = 389.9388
nvar$freq[6] = 248.5434
nvar$freq[7] = 160.7509
nvar$freq[8] = 757.3718
nvar$freq[9] = 253.4027
nvar$freq[10] = 106.7115
nvar$freq[11] = 178.4917

wordcloud(nvar$var, nvar$freq, min.freq=0,random.order=TRUE, random.color=TRUE, rot.per=.3,
          scale=c(4,0.6),ordered.colors=TRUE, colors="blue")

# == Echantillonnage (Apprentissage - Test) ===========================================

set.seed(0)
data10 = data5[,c(-5)]
data10$Group21[data10$Group2 == "L"] = "LOPTU"
data10$Group21[data10$Group2 == "M"] = "M"
data10$Group21[data10$Group2 == "N"] = "NQ"
data10$Group21[data10$Group2 == "O"] = "LOPTU"
data10$Group21[data10$Group2 == "P"] = "LOPTU"
data10$Group21[data10$Group2 == "Q"] = "NQ"
data10$Group21[data10$Group2 == "R"] = "R"
data10$Group21[data10$Group2 == "S"] = "S"
data10$Group21[data10$Group2 == "T"] = "LOPTU"
data10$Group21[data10$Group2 == "U"] = "LOPTU"
data10$Group21 = as.factor(data10$Group21)

# Génération d'un vecteur aléatoire
alea = runif(nrow(data10))

test = subset(data10, (alea<quantile(alea,0.2)))
apprentissage = subset(data10, (alea>=quantile(alea,0.2)))


# == Modélisation ===========================================

## Régression logistique

#on effectue la régression avec toutes les variables
reg = glm (Surv1 ~offset(log(Exppdays))+CBonus+CAge+CGroup1+Occupation+CPoldur+Type+Group21+CValue+Category+Adind, data =apprentissage , family = binomial (link ="logit"))

#on prend le critère BIC pour savoir lesquels
selection = stepAIC(reg, k=log(nrow(data10)))

summary(selection)
pred1 = predict(selection,newdata=apprentissage, type="response")
pred2 = predict(selection,newdata=test, type="response")
pred3 = prediction(pred1,apprentissage$Surv1)
pred4 = prediction(pred2,test$Surv1)
performance(pred3,"auc")
plot(performance(pred3,"tpr","fpr"), main="ROC sur base d'apprentissage", col="green")
abline(a=0,b=1, col="blue")
text(0.35, 0.6,  "AUC = 76,28 %", cex=1.65, pos=3,col="red")
performance(pred4,"auc")
plot(performance(pred4,"tpr","fpr"), main="ROC sur base test", col="green")
abline(a=0,b=1, col="blue")
text(0.35, 0.6,  "AUC = 75,30 %", cex=1.65, pos=3,col="red")




#=========================prévision abec la base pricing
previ=pricing

#Aucun doublon
table(duplicated(previ))


#on change les modalités
previ$CAge = cut(previ$Age, breaks = c(18, 29, 47,75), include.lowest = TRUE)
previ$CBonus = cut(previ$Bonus, breaks = c(-50, -36, -16, 14, 64,150), include.lowest = TRUE)
previ$CGroup1 = cut(previ$Group1, breaks = c(1, 9, 15, 20), include.lowest = TRUE)
previ$CPoldur = cut(previ$Poldur, breaks = c(0, 0.5, 4,15) , include.lowest = TRUE)
previ$CValue = cut(previ$Value, breaks = c(1000, 12999,49996) , include.lowest = TRUE)


#on transforme density en numéric
previ$Density=as.numeric(as.character(previ$Density))
previ$CDensity = cut(previ$Density, breaks = c(0,77.99,162.99,237.99,297.40) , include.lowest = TRUE)
table(previ$CDensity)/nrow(previ)


previ$Group21[previ$Group2 == "L"] = "LOPTU"
previ$Group21[previ$Group2 == "M"] = "M"
previ$Group21[previ$Group2 == "N"] = "NQ"
previ$Group21[previ$Group2 == "O"] = "LOPTU"
previ$Group21[previ$Group2 == "P"] = "LOPTU"
previ$Group21[previ$Group2 == "Q"] = "NQ"
previ$Group21[previ$Group2 == "R"] = "R"
previ$Group21[previ$Group2 == "S"] = "S"
previ$Group21[previ$Group2 == "T"] = "LOPTU"
previ$Group21[previ$Group2 == "U"] = "LOPTU"
previ$Group21 = as.factor(previ$Group21)

#on rajoute l'exposition
previ$Exppdays=rep(365,nrow(previ))



predPricing = predict(selection,newdata=previ, type="response")
base_previ=cbind.data.frame(previ$PolNum,predPricing)
names(base_previ)=c("PolNum", "Proba1")

write.csv(base_previ, file = "prevision.csv")






## Random Forest

cl = makeCluster(4)
registerDoParallel(cl)
rf = foreach(ntree=rep(20, 4), .combine=combine, .packages='randomForest') %dopar% {
  randomForest((Surv1==1)~Type+Category+Occupation+Adind+Group21+CAge+CGroup1+CBonus+CPoldur+CValue+offset(Exppdays),
               data = apprentissage, nodesize=20,
               ntree=ntree, importance=TRUE, keep.forest=TRUE)
}
stopCluster(cl)

rf1 = randomForest((Surv1==1)~Type+Category+Occupation+Adind+Group21+CAge+CGroup1+CBonus+CPoldur+CValue+offset(Exppdays),
               data = apprentissage, 
               ntree=1000, importance=TRUE, keep.forest=TRUE)

varImpPlot(rf1,main="") 
importance (rf1) 

s3 = predict(rf1, newdata = apprentissage,type="response")
pred = predict(rf1, newdata = test, type="response")
table(pred, test$Surv1)
s4 = predict(rf1,test, type="response")
pred3 = prediction(s3,apprentissage$Surv1)
pred4 = prediction(pred,test$Surv1)


rf1.imp = importance(rf1,type=1)[order(importance(rf1,type=1), decreasing=TRUE),]
par(mar = c(8, 4, 4, 0))
barplot(rf1.imp, col = gray(0:nrow(rf1$importance)/nrow(rf1$importance)),
        ylab='Importance', ylim=c(0,30),cex.names = 0.8, las=3)
title(main = list("Importance des variables", font = 1, cex = 1.2))



performance(pred3,"auc")
plot(performance(pred3,"tpr","fpr"), main="ROC sur base d'apprentissage", col="green")
abline(a=0,b=1, col="blue")
text(0.35, 0.6,  "AUC = 94,07 %", cex=1.65, pos=3,col="red")



# == Comparaison des deux modèles ===========================================

performance(pred4,"auc")
plot(performance(pred4,"tpr","fpr"))
abline(a=0,b=1)

roc=plot.roc(test$Surv1,pred4,main="",percent=TRUE, ci=TRUE)
roc.se=ci.se(roc, specificities = seq(0,100,5))






# appel foreach avec parallélisation
library(parallel)
detectCores()
detectCores(logical=FALSE)
library(doSNOW)
cl = makeCluster(2) #change the 2 to your number of physical CPU cores
registerDoSNOW(cl)

#rf <- foreach(ntree=rep(250, 4), .combine=combine, .packages='randomForest') %dopar% randomForest(x, y, ntree=ntree)
ptm = proc.time()
rf = foreach(ntree=rep(25, 4), .combine=combine, .packages='randomForest') %dopar% 
      randomForest((Surv1==1)~Type+Category+Occupation+Adind+Group21+CAge+CGroup1+CBonus+CPoldur+CValue+offset(Exppdays),
               data = apprentissage, nodesize=5,
               ntree=ntree, mtry=3, replace=T, importance=TRUE, keep.forest=TRUE)
proc.time() - ptm

# fin parallélisation
stopCluster(cl)

summary(rf)
]





reg = glm(Surv1~Age,data=data2,family=binomial) 
summary(reg) 

y=summaryBy(Surv1~Age, data2)
plot(y, col="red", xlab="Age")
abline(h=mean(y$Surv1.mean), col="gray", lty=2)
abline(lm(Surv1~Age, data2), col="blue")

AGE=c(18,25,35,50,65,80,100) 
cut_logistic = glm(Surv1~cut(Age, breaks=AGE),data=data2,family=binomial)

Age2 = seq(18,75,10)

summary(cut_logistic)
plot(Age2,cut_logistic, type="l")
cut_logistic

plot(summaryBy(Surv1~Value, data2), type="l", xlab="Value")
plot(summaryBy(Surv1~Density, data2), type="l", xlab="Density")
plot(summaryBy(Surv1~Bonus, data2), type="l", xlab="Bonus")
plot(summaryBy(Surv1~Poldur, data2), type="l", xlab="Poldur")












donnees = base_ensae_1[ , c(-1,-13,-17,-18,-20)]




donnees2 = donnees
str(donnees2)
donnees2$Value = log(donnees2$Value)
donnees2$CalYear=as.factor(donnees2$CalYear)
donnees2$Group1=as.factor(donnees2$Group1)
donnees2$Adind=as.factor(donnees2$Adind)







# == Régression logistique ===========================================

logistique = glm(formula = Surv1 ~ ., family = binomial (link ="logit"), data = donnees2)
logistique = glm(formula = Surv1 ~Age+Gender+CalYear, family = binomial (link ="logit"), data = donnees2)
summary(logistique)



